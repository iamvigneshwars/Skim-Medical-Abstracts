{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5f1546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 19:21:57.644306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a7a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = layers.experimental.preprocessing.TextVectorization(max_tokens=68000,\n",
    "                                                                 output_sequence_length=55) # 95% sentences contain 55 words as seen in data analysis.\n",
    "\n",
    "vectorizer_char = layers.experimental.preprocessing.TextVectorization(max_tokens =60,\n",
    "                                    output_sequence_length = 300, # 95% of the sentences have ~300 chars\n",
    "                                    name = 'Character_vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9291e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Embedding layer\n",
    "embedding_layer = layers.Embedding(\n",
    "    64843,\n",
    "    300,\n",
    "    trainable=False,\n",
    "    name = \"Pre_trained\"\n",
    ")\n",
    "\n",
    "# Character Embeddings layer \n",
    "char_layer = layers.Embedding(input_dim = 28,\n",
    "                             output_dim = 30,\n",
    "                             name=\"char_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0e79ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Attention layer\n",
    "class attention(layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,intput_emb):\n",
    "        et=tf.keras.backend.squeeze(tf.keras.backend.tanh(tf.keras.backend.dot(intput_emb,self.W)+self.b),axis=-1)\n",
    "        at=tf.keras.backend.softmax(et)\n",
    "        at=tf.keras.backend.expand_dims(at,axis=-1)\n",
    "        return intput_emb*at\n",
    "    \n",
    "# THE MODEL:\n",
    "\n",
    "# Word Embeddings Model\n",
    "sent_inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "sent_vec = vectorizer(sent_inputs)\n",
    "word_embeddings = embedding_layer(sent_vec)\n",
    "word_layer_2= layers.Bidirectional(layers.LSTM(128, return_sequences = True))(word_embeddings)\n",
    "attention_layer=attention()(word_layer_2)\n",
    "word_model = tf.keras.Model(inputs=sent_inputs,\n",
    "                            outputs=attention_layer)\n",
    "\n",
    "# Character Embeddings Model\n",
    "char_inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "char_vectorizer = vectorizer_char(char_inputs)\n",
    "char_embeddings = char_layer(char_vectorizer)\n",
    "char_layer_1= layers.Bidirectional(layers.LSTM(128, return_sequences=True))(char_embeddings) \n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                          outputs=char_layer_1)\n",
    "\n",
    "# Position model\n",
    "position_inputs = layers.Input(shape=(460,), dtype = tf.int64)\n",
    "pos_dense = layers.Dense(64, activation = 'relu')(position_inputs)\n",
    "pos_model = tf.keras.Model(position_inputs, pos_dense)\n",
    "\n",
    "word_char_layer = layers.Concatenate(axis =1)([attention_layer,\n",
    "                                        char_layer_1])\n",
    "\n",
    "word_char_lstm = layers.Bidirectional(layers.LSTM(128))(word_char_layer)\n",
    "word_char_dropout = layers.Dropout(0.5)(word_char_lstm)\n",
    "\n",
    "hybrid_layer = layers.Concatenate(name=\"word_char_pos\")([word_char_dropout,\n",
    "                                                        pos_model.output])\n",
    "\n",
    "output = layers.Dense(5, activation = 'softmax')(hybrid_layer)\n",
    "model = tf.keras.Model(inputs = [word_model.input,\n",
    "                                 char_model.input,\n",
    "                                 pos_model.input],\n",
    "                       outputs =  output)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing= 0.3),\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948ecac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f53a01b6a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ed277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d1415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 19:22:21.109493: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-13 19:22:21.110287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-13 19:22:21.214805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.215401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-01-13 19:22:21.215458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 19:22:21.220541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-13 19:22:21.220689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-13 19:22:21.225005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-13 19:22:21.225846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-13 19:22:21.231181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-13 19:22:21.234421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-13 19:22:21.245978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-13 19:22:21.246333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.246932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.247296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-13 19:22:21.248366: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-13 19:22:21.249023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.249441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-01-13 19:22:21.249487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 19:22:21.249544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-13 19:22:21.249590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-13 19:22:21.249633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-13 19:22:21.249676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-13 19:22:21.249718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-13 19:22:21.249760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-13 19:22:21.249803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-13 19:22:21.249949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.250430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.250786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-13 19:22:21.250848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-13 19:22:21.680494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-13 19:22:21.680517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-13 19:22:21.680523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-13 19:22:21.680709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.680889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.681027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 19:22:21.681137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3582 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-01-13 19:22:21.681425: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "model = transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1366caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "one_hot = joblib.load('one_hot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43ebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77a3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#one_hot = OneHotEncoder()\n",
    "def classify(data, model):\n",
    "    classes = [\"BACKGROUND\", \"CONCLUSIONS\", \"METHODS\", \"OBJECTIVE\", \"RESULTS\"]\n",
    "    \n",
    "    data = sent_tokenize(data)\n",
    "    \n",
    "    abstracts = [] # To store the dictonaries\n",
    "\n",
    "    for line_no, abst_lines in enumerate(data):\n",
    "        each_line = {} \n",
    "        each_line['position'] = str(line_no+1) +\"_of_\"+ str(len(data))\n",
    "        each_line[\"text\"] = abst_lines # to get the text of sentence in convert to lower\n",
    "        abstracts.append(each_line) # add dictionary to list of abstracts.\n",
    "    # reset the sample lines for next abstract.\n",
    "    def split(text):\n",
    "        return ' '.join(list(text))\n",
    "    abstract = pd.DataFrame(abstracts)  \n",
    "    \n",
    "    abs_sent = abstract.text\n",
    "    abs_char = abstract.text.apply(split)\n",
    "    abs_pos = one_hot.transform(np.expand_dims(abstract.position, axis = 1)).toarray()\n",
    "    \n",
    "    #abs_sent= vectorizer(abs_sent)\n",
    "    #abs_char = vectorizer_char(abs_char)\n",
    "    \n",
    "    abs_pred_probs = model.predict(x = (abs_sent,\n",
    "                                    abs_char,\n",
    "                                    abs_pos))\n",
    "    \n",
    "    abs_preds = tf.argmax(abs_pred_probs, axis=1)\n",
    "    abs_pred_classes = [classes[i] for i in abs_preds]\n",
    "    \n",
    "    for i , line in enumerate(data):\n",
    "        print(abs_pred_classes[i],\": \")\n",
    "        print(line, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f46846",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_1 = \" We aimed to establish an acute treatment protocol to increase serum vitamin D, evaluate the effectiveness of vitamin D3 supplementation, and reveal the potential mechanisms in COVID-19.  We retrospectively analyzed the data of 867 COVID-19 cases. Then, a prospective study was conducted, including 23 healthy individuals and 210 cases. A total of 163 cases had vitamin D supplementation, and 95 were followed for 14 days. Clinical outcomes, routine blood biomarkers, serum levels of vitamin D metabolism, and action mechanism-related parameters were evaluated.  Our treatment protocol increased the serum 25OHD levels significantly to above 30 ng/mL within two weeks. COVID-19 cases (no comorbidities, no vitamin D treatment, 25OHD <30 ng/mL) had 1.9-fold increased risk of having hospitalization longer than 8 days compared with the cases with comorbidities and vitamin D treatment. Having vitamin D treatment decreased the mortality rate by 2.14 times. The correlation analysis of specific serum biomarkers with 25OHD indicated that the vitamin D action in COVID-19 might involve regulation of INOS1, IL1B, IFNg, cathelicidin-LL37, and ICAM1.  Vitamin D treatment shortened hospital stay and decreased mortality in COVID-19 cases, even in the existence of comorbidities. Vitamin D supplementation is effective on various target parameters; therefore, it is essential for COVID-19 treatment. \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a15da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 19:22:30.426745: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-13 19:22:30.453947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499950000 Hz\n",
      "2022-01-13 19:22:31.907973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-13 19:22:32.066997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACKGROUND : \n",
      " We aimed to establish an acute treatment protocol to increase serum vitamin D, evaluate the effectiveness of vitamin D3 supplementation, and reveal the potential mechanisms in COVID-19. \n",
      "\n",
      "METHODS : \n",
      "We retrospectively analyzed the data of 867 COVID-19 cases. \n",
      "\n",
      "METHODS : \n",
      "Then, a prospective study was conducted, including 23 healthy individuals and 210 cases. \n",
      "\n",
      "RESULTS : \n",
      "A total of 163 cases had vitamin D supplementation, and 95 were followed for 14 days. \n",
      "\n",
      "METHODS : \n",
      "Clinical outcomes, routine blood biomarkers, serum levels of vitamin D metabolism, and action mechanism-related parameters were evaluated. \n",
      "\n",
      "RESULTS : \n",
      "Our treatment protocol increased the serum 25OHD levels significantly to above 30 ng/mL within two weeks. \n",
      "\n",
      "RESULTS : \n",
      "COVID-19 cases (no comorbidities, no vitamin D treatment, 25OHD <30 ng/mL) had 1.9-fold increased risk of having hospitalization longer than 8 days compared with the cases with comorbidities and vitamin D treatment. \n",
      "\n",
      "RESULTS : \n",
      "Having vitamin D treatment decreased the mortality rate by 2.14 times. \n",
      "\n",
      "RESULTS : \n",
      "The correlation analysis of specific serum biomarkers with 25OHD indicated that the vitamin D action in COVID-19 might involve regulation of INOS1, IL1B, IFNg, cathelicidin-LL37, and ICAM1. \n",
      "\n",
      "CONCLUSIONS : \n",
      "Vitamin D treatment shortened hospital stay and decreased mortality in COVID-19 cases, even in the existence of comorbidities. \n",
      "\n",
      "CONCLUSIONS : \n",
      "Vitamin D supplementation is effective on various target parameters; therefore, it is essential for COVID-19 treatment. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classify(abstract_1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9105c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
